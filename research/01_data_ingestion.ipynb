{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\New folder\\\\TB-Diagnosis-CNN\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\New folder\\\\TB-Diagnosis-CNN'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TBcnnClassifier.constants import *\n",
    "from TBcnnClassifier.utils.common import read_yaml, create_directories\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "import zipfile\n",
    "from TBcnnClassifier import logger\n",
    "from TBcnnClassifier.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"your-access-key\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"your-secret-access-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "        session = boto3.resource(\n",
    "            service_name='s3',\n",
    "            region_name='eu-north-1',\n",
    "            aws_access_key_id='AKIAWLYTVYE57LST7NEW',\n",
    "            aws_secret_access_key='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'\n",
    "        )\n",
    "        self.s3_client = session.meta.client\n",
    "\n",
    "    \n",
    "    def download_file(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            bucket_name = 'tbdatabucket'\n",
    "            object_key = 'TB_Chest_Radiography_Database.zip'\n",
    "            self.s3_client.download_file(bucket_name, object_key, self.config.local_data_file)\n",
    "            logger.info(f\"File downloaded from S3 bucket: {self.config.local_data_file}\")\n",
    "        else:\n",
    "            logger.info(f\"File already exists of size: {get_size(Path(self.config.local_data_file))}\")\n",
    "\n",
    "    \n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://tbdatabucket.s3.eu-north-1.amazonaws.com/TB_Chest_Radiography_Database.zip', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}}\n",
      "[2023-06-28 04:38:16,995: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "{'key': 'val'}\n",
      "[2023-06-28 04:38:17,001: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-06-28 04:38:17,006: INFO: common: created directory at: artifacts]\n",
      "[2023-06-28 04:38:17,010: INFO: common: created directory at: artifacts/data_ingestion]\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (404) when calling the HeadObject operation: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     data_ingestion\u001b[39m.\u001b[39mextract_zip_file()\n\u001b[0;32m      7\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[43], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     data_ingestion_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_data_ingestion_config()\n\u001b[0;32m      4\u001b[0m     data_ingestion \u001b[39m=\u001b[39m DataIngestion(config\u001b[39m=\u001b[39mdata_ingestion_config)\n\u001b[1;32m----> 5\u001b[0m     data_ingestion\u001b[39m.\u001b[39;49mdownload_file()\n\u001b[0;32m      6\u001b[0m     data_ingestion\u001b[39m.\u001b[39mextract_zip_file()\n\u001b[0;32m      7\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[42], line 17\u001b[0m, in \u001b[0;36mDataIngestion.download_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m     bucket_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtbdatabucket\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     16\u001b[0m     object_key \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39ms3://tbdatabucket/TB_Chest_Radiography_Database.zip\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 17\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ms3_client\u001b[39m.\u001b[39;49mdownload_file(bucket_name, object_key, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mlocal_data_file)\n\u001b[0;32m     18\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile downloaded from S3 bucket: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlocal_data_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\tbcnn\\lib\\site-packages\\boto3\\s3\\inject.py:190\u001b[0m, in \u001b[0;36mdownload_file\u001b[1;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[39mUsage::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39m    transfer.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39mwith\u001b[39;00m S3Transfer(\u001b[39mself\u001b[39m, Config) \u001b[39mas\u001b[39;00m transfer:\n\u001b[1;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m transfer\u001b[39m.\u001b[39;49mdownload_file(\n\u001b[0;32m    191\u001b[0m         bucket\u001b[39m=\u001b[39;49mBucket,\n\u001b[0;32m    192\u001b[0m         key\u001b[39m=\u001b[39;49mKey,\n\u001b[0;32m    193\u001b[0m         filename\u001b[39m=\u001b[39;49mFilename,\n\u001b[0;32m    194\u001b[0m         extra_args\u001b[39m=\u001b[39;49mExtraArgs,\n\u001b[0;32m    195\u001b[0m         callback\u001b[39m=\u001b[39;49mCallback,\n\u001b[0;32m    196\u001b[0m     )\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\tbcnn\\lib\\site-packages\\boto3\\s3\\transfer.py:326\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[1;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[0;32m    322\u001b[0m future \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager\u001b[39m.\u001b[39mdownload(\n\u001b[0;32m    323\u001b[0m     bucket, key, filename, extra_args, subscribers\n\u001b[0;32m    324\u001b[0m )\n\u001b[0;32m    325\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 326\u001b[0m     future\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    327\u001b[0m \u001b[39m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[39m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[39m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# their own retries.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\tbcnn\\lib\\site-packages\\s3transfer\\futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresult\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     99\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m         \u001b[39m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[0;32m    101\u001b[0m         \u001b[39m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[0;32m    102\u001b[0m         \u001b[39m# out of this and propagate the exception.\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coordinator\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    104\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    105\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\tbcnn\\lib\\site-packages\\s3transfer\\futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# final result.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\tbcnn\\lib\\site-packages\\s3transfer\\tasks.py:269\u001b[0m, in \u001b[0;36mSubmissionTask._main\u001b[1;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_coordinator\u001b[39m.\u001b[39mset_status_to_running()\n\u001b[0;32m    267\u001b[0m     \u001b[39m# Call the submit method to start submitting tasks to execute the\u001b[39;00m\n\u001b[0;32m    268\u001b[0m     \u001b[39m# transfer.\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_submit(transfer_future\u001b[39m=\u001b[39mtransfer_future, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    271\u001b[0m     \u001b[39m# If there was an exception raised during the submission of task\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[39m# there is a chance that the final task that signals if a transfer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m \n\u001b[0;32m    282\u001b[0m     \u001b[39m# Set the exception, that caused the process to fail.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_and_set_exception(e)\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\tbcnn\\lib\\site-packages\\s3transfer\\download.py:354\u001b[0m, in \u001b[0;36mDownloadSubmissionTask._submit\u001b[1;34m(self, client, config, osutil, request_executor, io_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m:param client: The client associated with the transfer manager\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39m    downloading streams\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m transfer_future\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39msize \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     \u001b[39m# If a size was not provided figure out the size for the\u001b[39;00m\n\u001b[0;32m    353\u001b[0m     \u001b[39m# user.\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mhead_object(\n\u001b[0;32m    355\u001b[0m         Bucket\u001b[39m=\u001b[39mtransfer_future\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mcall_args\u001b[39m.\u001b[39mbucket,\n\u001b[0;32m    356\u001b[0m         Key\u001b[39m=\u001b[39mtransfer_future\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mcall_args\u001b[39m.\u001b[39mkey,\n\u001b[0;32m    357\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtransfer_future\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mcall_args\u001b[39m.\u001b[39mextra_args,\n\u001b[0;32m    358\u001b[0m     )\n\u001b[0;32m    359\u001b[0m     transfer_future\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mprovide_transfer_size(\n\u001b[0;32m    360\u001b[0m         response[\u001b[39m'\u001b[39m\u001b[39mContentLength\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    361\u001b[0m     )\n\u001b[0;32m    363\u001b[0m download_output_manager \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_download_output_manager_cls(\n\u001b[0;32m    364\u001b[0m     transfer_future, osutil\n\u001b[0;32m    365\u001b[0m )(osutil, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_coordinator, io_executor)\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\tbcnn\\lib\\site-packages\\botocore\\client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[0;32m    529\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[1;32mf:\\Anaconda\\envs\\tbcnn\\lib\\site-packages\\botocore\\client.py:964\u001b[0m, in \u001b[0;36m_make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    961\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m         \u001b[39mreturn\u001b[39;00m parsed_response\n\u001b[1;32m--> 964\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\u001b[39mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[0;32m    965\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    966\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_endpoint\u001b[39m.\u001b[39mmake_request(operation_model, request_dict)\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (404) when calling the HeadObject operation: Not Found"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
